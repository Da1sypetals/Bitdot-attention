# Bitdot-attention
## Requirements
```
torch>=2.7
```
## Files
```
fastflex.py: correct implementation
```
Attention flag compression optimize is TBD.