# Bitdot-attention
## Requirements
```
torch>=2.7
```
## Files
```
test.py: prompt and design, correct implementation
fastflex.py: faster implementation, but DOES NOT SEEM CORRECT.
```
Attention flag compression optimize is TBD.